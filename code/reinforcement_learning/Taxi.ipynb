{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRHvKzny0uEU"
      },
      "source": [
        "# Practical Session: Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45WKVaNv0uEW"
      },
      "source": [
        "In this practical session, you will implement the famous [Q-Learning](https://link.springer.com/content/pdf/10.1007/BF00992698.pdf) algorithm and test it in various environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBY-IqGn0uEY"
      },
      "source": [
        "## Taxi V3\n",
        "\n",
        "The taxi problem was first introduced in [Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition](https://arxiv.org/abs/cs/9905014).  \n",
        "In this environment, the agent controls a taxi whose job is to pick up a passenger at one location and drop him off in his target location.  \n",
        "Dropping of the passenger to its destination leads to a +20 reward.  \n",
        "To encourage the agent to be as fast as possible, it receives a deceptive reward of -1 at each step.  \n",
        "It will also receive a -10 penalty reward if it takes an illegal 'pick-up' or drop-off' action.  \n",
        "Let's instantiate a Taxi-V3 environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5hYJBID00uEZ",
        "outputId": "b76963df-b098-4e8d-ba6a-97a6be231c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctQ0Y-2C0uEZ"
      },
      "source": [
        "The taxi is represented in <span style=\"color:yellow\">yellow</span> when empty and in <span style=\"color:green\">green</span> when full.  \n",
        "The passenger is represented in <span style=\"color:blue\">blue</span> and his destination in <span style=\"color:magenta\">magenta</span>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nplhky0Y0uEb"
      },
      "source": [
        "**Observations**: There are 500 discrete states since there are 25 taxi positions, five possible passenger locations (including the case when the passenger is in the taxi), and four destination locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MMsH_AtP0uEb",
        "outputId": "4b2e5be3-90e7-464a-85ae-d6d5b6d25775",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Space Discrete(500)\n"
          ]
        }
      ],
      "source": [
        "print(f\"State Space {env.observation_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T8no1NF0uEb"
      },
      "source": [
        "The agent controling the *taxi* has six discrete and deterministic possibles actions:  \n",
        "*  0: *move south*\n",
        "*  1: *move north*\n",
        "*  2: *move east*\n",
        "*  3: *move west*\n",
        "*  4: *pickup passenger*\n",
        "*  5: *drop off passenger*  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gmjhODht0uEc",
        "outputId": "d3912d93-8176-4fed-bada-a92879646a24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Action Space {env.action_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pTGPFy0uEg"
      },
      "source": [
        "Here is a little method to vizualize our taxi's trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "37iD8TZz0uEh"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def display_trajectory(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iikkv-cn0uEh"
      },
      "source": [
        "# Random agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwV_VoEz0uEh"
      },
      "source": [
        "The following code shows how to run an episode with an agent taking random actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yEdfewxh0uEj",
        "outputId": "78baaa63-ee35-443a-e246-57a698ab1902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: |\u001b[43m \u001b[0m: :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "\n",
            "Timestep: 200\n",
            "State: 54\n",
            "Reward: -1\n"
          ]
        }
      ],
      "source": [
        "frames = [] # for animation\n",
        "\n",
        "env.reset()\n",
        "while True:\n",
        "    # draw a random action from the action space\n",
        "    action = env.action_space.sample()\n",
        "    # the step method takes an action as input and returns 4 variables described in the OpenAI section\n",
        "    state, reward, done, info = env.step(action)\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'reward': reward\n",
        "        })\n",
        "    #if done is True then the episode is over\n",
        "    if done == True:\n",
        "        break\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tthbYU810uEj"
      },
      "source": [
        "## Human policy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kIxpqTAM0uEj",
        "outputId": "0721a883-bb4b-4898-c322-28c0f9869d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[43m \u001b[0m: |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLA-sqdh0uEn"
      },
      "source": [
        "We just saw a random policy. Let's now check on your policy.  \n",
        "Using the possible actions, make a little script to take the client to his destination and visualize it with the `display_frames` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ix_-0DkD0uEo",
        "outputId": "cda623d8-ca28-417e-93b6-45e4aca2d039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 13\n",
            "State: 8\n",
            "Reward: -10\n"
          ]
        }
      ],
      "source": [
        "frames = [] \n",
        "actions = [1,1,2,4,3,3,0,0,3,3,1,1,5]\n",
        "\n",
        "for a in actions:\n",
        "    state, reward, done, info = env.step(a)\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'reward': reward\n",
        "        })\n",
        "\n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlXrScj80uEp"
      },
      "source": [
        "# Q-learning\n",
        "Let's now try to solve the TaxiV3 problem using the Q-learing algorithm.\n",
        "![](https://github.com/DavidBert/N7-techno-IA/blob/master/code/reinforcement_learning/images/q-learning.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DupJU8dJ0uEp"
      },
      "source": [
        "Fill the `q_learning` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BvzCja8M0uEp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "\n",
        "def print_running_mean(training_rewards, i):\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(15,3))\n",
        "    plt.plot(pd.Series(training_rewards[:i]).rolling(100).mean())\n",
        "    plt.title(\"Rewards running mean on last 100 episodes\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def q_learning(env, alpha, gamma, epsilon, nb_episodes):\n",
        "    nb_states = env.observation_space.n\n",
        "    nb_actions = env.action_space.n\n",
        "    q_table = np.zeros([nb_states, nb_actions])\n",
        "    training_rewards = np.zeros(nb_episodes)\n",
        "    for i in range(nb_episodes):\n",
        "        s = env.reset()\n",
        "\n",
        "        while True:\n",
        "          a = np.argmax(q_table[s, :])\n",
        "          s_prime, reward, done, _ = env.step(a)\n",
        "\n",
        "          q_table[s, a] = q_table[s, a] + alpha * (reward + gamma * np.max(q_table[s_prime, :]) - q_table[s, a])\n",
        "          s = s_prime\n",
        "\n",
        "          training_rewards[i] += reward\n",
        "          if done:\n",
        "              break\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print_running_mean(training_rewards, i)\n",
        "\n",
        "    return q_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apU9ASiq0uEq"
      },
      "source": [
        "Train your q-table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qQ-cXiWR0uEq",
        "outputId": "187883bc-1651-4a88-fae5-c07a93f41f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "nb_episodes = 5000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "q_table = q_learning(env, alpha, gamma, epsilon, nb_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQE6igQq0uEq"
      },
      "source": [
        "Let us have a look at the learned policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MxbW8fo60uEr",
        "outputId": "59c26b62-9eca-43d4-b69f-76a780504d28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-65401901155a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   frames.append({\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ansi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m'state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m'reward'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/toy_text/taxi.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mtaxi_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaxi_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "env.reset()\n",
        "frames = [] # for animation\n",
        "timesteps = 0\n",
        "while True:\n",
        "  A = np.argmax(q_table[s, a] for )\n",
        "  state, reward, done, info = env.step(A)\n",
        "  frames.append({\n",
        "    'frame': env.render(mode='ansi'),\n",
        "    'state': state,\n",
        "    'reward': reward\n",
        "    })\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDpIHIus0uEr"
      },
      "source": [
        "# Frozen lake\n",
        "Now, try your algoithm on frozen lake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VsH-zAC0uEr"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "env = gym.make(\"FrozenLake8x8-v0\")\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBrAsMu0uEs"
      },
      "outputs": [],
      "source": [
        "nb_episodes = 20000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "q_table = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv6em7-G0uEs"
      },
      "source": [
        "Your agent has probably not reached a satisfying policy.  \n",
        "This is due to the lack of exploration induced by the $\\epsilon$-greedy policy.\n",
        "Fixing $\\epsilon$ to 0.1 is not sufficient in Frozen Lake. The agent does not explore enougth and thus never receives a positive feedback.  \n",
        "A simple solution would be to use a decaying epsilon from 1 to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8oxHiDy0uEs"
      },
      "outputs": [],
      "source": [
        "decay_rates = [0.9, 0.99, 0.9995, 0.9999]\n",
        "eps_min = 0.1\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for decay_rate in decay_rates:\n",
        "    eps_list = []\n",
        "    test_eps = 1\n",
        "    for _ in range(nb_episodes):\n",
        "        test_eps = max(test_eps * decay_rate, eps_min)\n",
        "        eps_list.append(test_eps)          \n",
        "    \n",
        "    plt.plot(eps_list, label='decay rate: {}'.format(decay_rate))\n",
        "\n",
        "plt.title('Effect of various decay rates')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('# of episodes')\n",
        "plt.ylabel('epsilon')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWin82po0uEt"
      },
      "source": [
        "Modify your `q_learning` function to decay the learning rate after each episode (don't forget to clip so it does not go below 0.1).\n",
        "Try your function with different values for `epsilon_decay`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pFaW5Mu0uEt"
      },
      "outputs": [],
      "source": [
        "def q_learning(env, alpha, gamma, epsilon_decay, nb_episodes):\n",
        "    epsilon = 1\n",
        "    min_epsilon = 0.1\n",
        "    nb_states = env.observation_space.n\n",
        "    nb_actions = env.action_space.n\n",
        "    q_table = np.zeros([nb_states, nb_actions])\n",
        "    training_rewards = np.zeros(nb_episodes)\n",
        "    for i in range(nb_episodes):\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "        if i % 100 == 0:\n",
        "            print_running_mean(training_rewards, i)\n",
        "            \n",
        "    return q_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZldeDW30uEt"
      },
      "outputs": [],
      "source": [
        "nb_episodes = 20000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon_decay = 0.9999\n",
        "\n",
        "q_table = q_learning(env, alpha, gamma, epsilon_decay, nb_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLzoGfcP0uEt"
      },
      "source": [
        "Let us have a look at the learned policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV2ZvSsC0uEu"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "frames = [] # for animation\n",
        "timesteps = 0\n",
        "state = env.reset()\n",
        "while True:\n",
        "    ...\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvZqoAr_0uEu"
      },
      "source": [
        "In these two environments, the State-space was discrete and small enough to learn the entire Q-table.\n",
        "In most cases, this State space is way too large to learn the Q-values for each state.  \n",
        "One solution is to learn an estimator of this Q-function.\n",
        "In the following practical session, you will adapt the Q-learning algorithm to uses neural networks as function approximators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHueCc040uEu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Taxi.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}