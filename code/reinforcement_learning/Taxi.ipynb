{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRHvKzny0uEU"
      },
      "source": [
        "# Practical Session: Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45WKVaNv0uEW"
      },
      "source": [
        "In this practical session, you will implement the famous [Q-Learning](https://link.springer.com/content/pdf/10.1007/BF00992698.pdf) algorithm and test it in various environments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBY-IqGn0uEY"
      },
      "source": [
        "## Taxi V3\n",
        "\n",
        "The taxi problem was first introduced in [Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition](https://arxiv.org/abs/cs/9905014).  \n",
        "In this environment, the agent controls a taxi whose job is to pick up a passenger at one location and drop him off in his target location.  \n",
        "Dropping of the passenger to its destination leads to a +20 reward.  \n",
        "To encourage the agent to be as fast as possible, it receives a deceptive reward of -1 at each step.  \n",
        "It will also receive a -10 penalty reward if it takes an illegal 'pick-up' or drop-off' action.  \n",
        "Let's instantiate a Taxi-V3 environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hYJBID00uEZ",
        "outputId": "b76963df-b098-4e8d-ba6a-97a6be231c43"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctQ0Y-2C0uEZ"
      },
      "source": [
        "The taxi is represented in <span style=\"color:yellow\">yellow</span> when empty and in <span style=\"color:green\">green</span> when full.  \n",
        "The passenger is represented in <span style=\"color:blue\">blue</span> and his destination in <span style=\"color:magenta\">magenta</span>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nplhky0Y0uEb"
      },
      "source": [
        "**Observations**: There are 500 discrete states since there are 25 taxi positions, five possible passenger locations (including the case when the passenger is in the taxi), and four destination locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMsH_AtP0uEb",
        "outputId": "4b2e5be3-90e7-464a-85ae-d6d5b6d25775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State Space Discrete(500)\n"
          ]
        }
      ],
      "source": [
        "print(f\"State Space {env.observation_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T8no1NF0uEb"
      },
      "source": [
        "The agent controling the *taxi* has six discrete and deterministic possibles actions:  \n",
        "*  0: *move south*\n",
        "*  1: *move north*\n",
        "*  2: *move east*\n",
        "*  3: *move west*\n",
        "*  4: *pickup passenger*\n",
        "*  5: *drop off passenger*  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmjhODht0uEc",
        "outputId": "d3912d93-8176-4fed-bada-a92879646a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Action Space {env.action_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pTGPFy0uEg"
      },
      "source": [
        "Here is a little method to vizualize our taxi's trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "37iD8TZz0uEh"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "\n",
        "def display_trajectory(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        sleep(.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iikkv-cn0uEh"
      },
      "source": [
        "# Random agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwV_VoEz0uEh"
      },
      "source": [
        "The following code shows how to run an episode with an agent taking random actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEdfewxh0uEj",
        "outputId": "78baaa63-ee35-443a-e246-57a698ab1902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: |\u001b[42m_\u001b[0m: :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "\n",
            "Timestep: 200\n",
            "State: 56\n",
            "Reward: -1\n"
          ]
        }
      ],
      "source": [
        "frames = [] # for animation\n",
        "\n",
        "env.reset()\n",
        "while True:\n",
        "    # draw a random action from the action space\n",
        "    action = env.action_space.sample()\n",
        "    # the step method takes an action as input and returns 4 variables described in the OpenAI section\n",
        "    state, reward, done, info = env.step(action)\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'reward': reward\n",
        "        })\n",
        "    #if done is True then the episode is over\n",
        "    if done == True:\n",
        "        break\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tthbYU810uEj"
      },
      "source": [
        "## Human policy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIxpqTAM0uEj",
        "outputId": "0721a883-bb4b-4898-c322-28c0f9869d11"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLA-sqdh0uEn"
      },
      "source": [
        "We just saw a random policy. Let's now check on your policy.  \n",
        "Using the possible actions, make a little script to take the client to his destination and visualize it with the `display_frames` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix_-0DkD0uEo",
        "outputId": "cda623d8-ca28-417e-93b6-45e4aca2d039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 13\n",
            "State: 134\n",
            "Reward: -10\n"
          ]
        }
      ],
      "source": [
        "frames = [] \n",
        "actions = [1,1,2,4,3,3,0,0,3,3,1,1,5]\n",
        "\n",
        "for a in actions:\n",
        "    state, reward, done, info = env.step(a)\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'reward': reward\n",
        "        })\n",
        "\n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlXrScj80uEp"
      },
      "source": [
        "# Q-learning\n",
        "Let's now try to solve the TaxiV3 problem using the Q-learing algorithm.\n",
        "![](https://github.com/DavidBert/N7-techno-IA/blob/master/code/reinforcement_learning/images/q-learning.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DupJU8dJ0uEp"
      },
      "source": [
        "Fill the `q_learning` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BvzCja8M0uEp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
            "/home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  other = LooseVersion(other)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "\n",
        "def print_running_mean(training_rewards, i):\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(15,3))\n",
        "    plt.plot(pd.Series(training_rewards[:i]).rolling(100).mean())\n",
        "    plt.title(\"Rewards running mean on last 100 episodes\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def q_learning(env, alpha, gamma, epsilon, nb_episodes):\n",
        "    nb_states = env.observation_space.n\n",
        "    nb_actions = env.action_space.n\n",
        "    q_table = np.zeros([nb_states, nb_actions])\n",
        "    training_rewards = np.zeros(nb_episodes)\n",
        "    for i in range(nb_episodes):\n",
        "        s = env.reset()\n",
        "\n",
        "        while True:\n",
        "          a = np.argmax(q_table[s, :])\n",
        "          s_prime, reward, done, _ = env.step(a)\n",
        "\n",
        "          q_table[s, a] = q_table[s, a] + alpha * (reward + gamma * np.max(q_table[s_prime, :]) - q_table[s, a])\n",
        "          s = s_prime\n",
        "\n",
        "          training_rewards[i] += reward\n",
        "          if done:\n",
        "              break\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print_running_mean(training_rewards, i)\n",
        "\n",
        "    return q_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apU9ASiq0uEq"
      },
      "source": [
        "Train your q-table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "qQ-cXiWR0uEq",
        "outputId": "187883bc-1651-4a88-fae5-c07a93f41f5b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "nb_episodes = 5000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "q_table = q_learning(env, alpha, gamma, epsilon, nb_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQE6igQq0uEq"
      },
      "source": [
        "Let us have a look at the learned policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "MxbW8fo60uEr",
        "outputId": "59c26b62-9eca-43d4-b69f-76a780504d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 13\n",
            "State: 0\n",
            "Reward: 20\n"
          ]
        }
      ],
      "source": [
        "state = env.reset()\n",
        "frames = [] # for animation\n",
        "timesteps = 0\n",
        "while True:\n",
        "  # draw a random action from the action space\n",
        "  action = np.argmax(q_table[state, :])\n",
        "  state, reward, done, info = env.step(action)\n",
        "  \n",
        "  frames.append({\n",
        "    'frame': env.render(mode='ansi'),\n",
        "    'state': state,\n",
        "    'reward': reward\n",
        "    })\n",
        "\n",
        "  if done : \n",
        "    break\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDpIHIus0uEr"
      },
      "source": [
        "# Frozen lake\n",
        "Now, try your algoithm on frozen lake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7VsH-zAC0uEr"
      },
      "outputs": [
        {
          "ename": "ResetNeeded",
          "evalue": "Cannot call `env.render()` before calling `env.reset()`, if this is a intended action, set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResetNeeded\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m/home/n7student/Documents/S4/Atelier IA/RL/Reinforcement-Learning/code/reinforcement_learning/Taxi.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/n7student/Documents/S4/Atelier%20IA/RL/Reinforcement-Learning/code/reinforcement_learning/Taxi.ipynb#ch0000026?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/n7student/Documents/S4/Atelier%20IA/RL/Reinforcement-Learning/code/reinforcement_learning/Taxi.ipynb#ch0000026?line=1'>2</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mFrozenLake8x8-v1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/n7student/Documents/S4/Atelier%20IA/RL/Reinforcement-Learning/code/reinforcement_learning/Taxi.ipynb#ch0000026?line=2'>3</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender()\n",
            "File \u001b[0;32m~/anaconda3/envs/gym/lib/python3.9/site-packages/gym/core.py:343\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/core.py?line=340'>341</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/core.py?line=341'>342</a>\u001b[0m     \u001b[39m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/core.py?line=342'>343</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:47\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=44'>45</a>\u001b[0m \u001b[39m\"\"\"Renders the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m---> <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=46'>47</a>\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=47'>48</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=48'>49</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=49'>50</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/n7student/anaconda3/envs/gym/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py?line=50'>51</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mrender(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[0;31mResetNeeded\u001b[0m: Cannot call `env.render()` before calling `env.reset()`, if this is a intended action, set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper."
          ]
        }
      ],
      "source": [
        "import gym\n",
        "env = gym.make(\"FrozenLake8x8-v1\")\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBrAsMu0uEs"
      },
      "outputs": [],
      "source": [
        "nb_episodes = 20000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "q_table = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv6em7-G0uEs"
      },
      "source": [
        "Your agent has probably not reached a satisfying policy.  \n",
        "This is due to the lack of exploration induced by the $\\epsilon$-greedy policy.\n",
        "Fixing $\\epsilon$ to 0.1 is not sufficient in Frozen Lake. The agent does not explore enougth and thus never receives a positive feedback.  \n",
        "A simple solution would be to use a decaying epsilon from 1 to 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8oxHiDy0uEs"
      },
      "outputs": [],
      "source": [
        "decay_rates = [0.9, 0.99, 0.9995, 0.9999]\n",
        "eps_min = 0.1\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for decay_rate in decay_rates:\n",
        "    eps_list = []\n",
        "    test_eps = 1\n",
        "    for _ in range(nb_episodes):\n",
        "        test_eps = max(test_eps * decay_rate, eps_min)\n",
        "        eps_list.append(test_eps)          \n",
        "    \n",
        "    plt.plot(eps_list, label='decay rate: {}'.format(decay_rate))\n",
        "\n",
        "plt.title('Effect of various decay rates')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('# of episodes')\n",
        "plt.ylabel('epsilon')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWin82po0uEt"
      },
      "source": [
        "Modify your `q_learning` function to decay the learning rate after each episode (don't forget to clip so it does not go below 0.1).\n",
        "Try your function with different values for `epsilon_decay`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pFaW5Mu0uEt"
      },
      "outputs": [],
      "source": [
        "def q_learning(env, alpha, gamma, epsilon_decay, nb_episodes):\n",
        "    epsilon = 1\n",
        "    min_epsilon = 0.1\n",
        "    nb_states = env.observation_space.n\n",
        "    nb_actions = env.action_space.n\n",
        "    q_table = np.zeros([nb_states, nb_actions])\n",
        "    training_rewards = np.zeros(nb_episodes)\n",
        "    for i in range(nb_episodes):\n",
        "        ...\n",
        "        ...\n",
        "        ...\n",
        "        if i % 100 == 0:\n",
        "            print_running_mean(training_rewards, i)\n",
        "            \n",
        "    return q_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZldeDW30uEt"
      },
      "outputs": [],
      "source": [
        "nb_episodes = 20000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon_decay = 0.9999\n",
        "\n",
        "q_table = q_learning(env, alpha, gamma, epsilon_decay, nb_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLzoGfcP0uEt"
      },
      "source": [
        "Let us have a look at the learned policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV2ZvSsC0uEu"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "frames = [] # for animation\n",
        "timesteps = 0\n",
        "state = env.reset()\n",
        "while True:\n",
        "    ...\n",
        "        \n",
        "display_trajectory(frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvZqoAr_0uEu"
      },
      "source": [
        "In these two environments, the State-space was discrete and small enough to learn the entire Q-table.\n",
        "In most cases, this State space is way too large to learn the Q-values for each state.  \n",
        "One solution is to learn an estimator of this Q-function.\n",
        "In the following practical session, you will adapt the Q-learning algorithm to uses neural networks as function approximators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHueCc040uEu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Taxi.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3b5367d8d8491bdefee5e6f82db73b5f8699223173e25001ec984e8a6adfa422"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('gym')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
